{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3377beff-881e-4463-a3b3-76a77cd5f6d8",
   "metadata": {
    "collapsed": false,
    "name": "cell23"
   },
   "source": [
    "# ðŸ§ª Hands-on Lab: Exploring Snowflake Data Science and ML Capabilities\n",
    "\n",
    "Welcome to this **Hands-on Lab**, where you'll get practical experience with some of Snowflakeâ€™s most powerful features for Data Science and Machine Learning development:\n",
    "\n",
    "### ðŸ”¹ Snowflake Notebooks  \n",
    "Learn how to interactively explore, analyze, and visualize data using Snowflake Notebooks â€” an integrated development environment (IDE) right within the Snowflake UI. With support for Python and SQL side by side, Notebooks make it easier than ever to build, test, and document your data workflows.\n",
    "\n",
    "### ðŸ”¹ Snowflake Cortex ML Functions  \n",
    "Unlock the power of Snowflake Cortex, a fully managed machine learning service. You'll discover how to apply pre-built Cortex ML functions for tasks like classification, translation, task completion, and more â€” all without leaving the Snowflake environment.\n",
    "\n",
    "### ðŸ”¹ Snowflake Model Registry  \n",
    "Take your ML projects to the next level with the **Model Registry**, which lets you manage and deploy custom models built inside or outside of Snowflake. Youâ€™ll learn how to register, version, and serve models, enabling seamless collaboration and production-ready deployments.\n",
    "\n",
    "---\n",
    "\n",
    "### âœ… By the end of this lab, you will:\n",
    "- Build and run interactive notebooks using Python and SQL  \n",
    "- Use Cortex ML functions to derive insights from raw data  \n",
    "- Register and deploy a custom machine learning model  \n",
    "---\n",
    "\n",
    "### ðŸ—“ï¸ Lab Agenda\n",
    "\n",
    "This hands-on lab is designed to guide you through the full cycle of building and operationalizing machine learning workflows directly in Snowflake. Below is the step-by-step agenda we'll follow:\n",
    "- 1ï¸âƒ£ Data Sources Description  \n",
    "- 2ï¸âƒ£ Data Visualization and Manipulation  \n",
    "- 3ï¸âƒ£ Snowflake ML Capabilities  \n",
    "- 4ï¸âƒ£ Snowflake Model Registry\n",
    "\n",
    "Letâ€™s dive in and start building with AI in the Data Cloud! â˜ï¸ðŸ’¡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb87b88f-ad75-4744-95e0-4a3c49834d92",
   "metadata": {
    "collapsed": false,
    "name": "cell24"
   },
   "source": [
    "## âš™ï¸ Lab Setup Instructions\n",
    "Before we dive into the hands-on lab, please follow the steps below to get your environment ready. These steps ensure you have access to the right tools, permissions, and datasets.\n",
    "\n",
    "1. Please make sure you are using the role ***TRAINING_03_2025_ROLE***\n",
    "2. Please validate that your notebook is prefixed with your first and last name.\n",
    "3. Click on the ***Packages*** button at the upper corner of the screen and make sure you have selected the following packages\n",
    "    - snowflake-ml-python==1.7.4\n",
    "    - python==3.9\n",
    "    - streamlit==1.39.1\n",
    "    - plotly==5.24.1\n",
    "4. Click on ***Notebook Settings*** in the ellipsis on the top right corner of the window and ensure you are using warehouse ***TRAINING_03_2025_WH_1*** or ***TRAINING_03_2025_WH_2*** as instructed by the lab professor.\n",
    "5. Finally, please change the variable ***schema_name*** bellow with the name of the schema prefix with your first and last name.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e252eea5-91a4-4217-b2b1-24ba04cc2b51",
   "metadata": {
    "language": "python",
    "name": "cell3"
   },
   "outputs": [],
   "source": [
    "# Import python packages\n",
    "from snowflake.ml.registry import Registry\n",
    "from snowflake.ml.modeling.xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from snowflake.snowpark.context import get_active_session\n",
    "import streamlit as st\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Disable warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# Get a Snowpark Session\n",
    "session = get_active_session()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8b6d1ce-c0fa-47cb-a8fa-18c16730518a",
   "metadata": {
    "collapsed": false,
    "name": "cell27"
   },
   "source": [
    "### âš ï¸ Important\n",
    "\n",
    "Be sure to **replace the schema name** in the sample code with **your own schema name** to avoid errors and ensure you're working within the correct context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396cfed4-146c-4a0a-a49d-1ff81975893b",
   "metadata": {
    "language": "python",
    "name": "cell25"
   },
   "outputs": [],
   "source": [
    "schema_name = 'add_your_schema_name_here'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849ad38-da1d-4c96-85a5-7a051a4ed6fa",
   "metadata": {
    "language": "sql",
    "name": "ENVIRONMENT"
   },
   "outputs": [],
   "source": [
    "-- CHANGE THIS TO USE THE ATTENDANCE SCHEMA.\n",
    "USE DATABASE HOL_LAB_DATASCIENCE;\n",
    "USE SCHEMA {{schema_name}};"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0acda1e-b11b-4138-9e08-0872bed567a6",
   "metadata": {
    "collapsed": false,
    "name": "cell28"
   },
   "source": [
    "# 1ï¸âƒ£ Data Sources Description \n",
    "- Overview of the dataset(s) used in this lab  \n",
    "- Schema and data types  \n",
    "- Use cases and business context for the analysis\n",
    "\n",
    "For this lab, we will use two demo tables:\n",
    "1. HOL_LAB_DATASCIENCE.LAB.CLUSTER_QUALIFICATION\n",
    "2. HOL_LAB_DATASCIENCE.LAB.pilot_1_e_commerce_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7967a4d8-8530-4b12-a7b3-eb6067cf817b",
   "metadata": {
    "language": "sql",
    "name": "cell6"
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "\tCLUSTER,\n",
    "\tCM_OWN_WAY,\n",
    "\tCM_SECURE_SURROUNDINGS,\n",
    "\tCM_GOOD_TIME,\n",
    "\tCM_FOLLOW_RULES,\n",
    "\tCM_DIFFERENT_PEOPLE,\n",
    "\tCM_SATISFACTION,\n",
    "\tCM_SUCCESSFUL,\n",
    "\tCM_DEVOTE_MYSELF,\n",
    "\tCM_TAKE_RISKS,\n",
    "\tCM_BE_IN_CHARGE\n",
    "FROM HOL_LAB_DATASCIENCE.LAB.CLUSTER_QUALIFICATION\n",
    "WHERE cluster is not null;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d91970-3bb1-492f-b284-67d2479c5e46",
   "metadata": {
    "language": "sql",
    "name": "cell1"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    key_voysen,\n",
    "    name_voysen,\n",
    "    brand_voysen,\n",
    "    name_source,\n",
    "    date_datetime,\n",
    "    review_translated_text,\n",
    "    topics \n",
    "FROM TRAINING_03_2025_DB.DEMO.PILOT_1_E_COMMERCE_COMMENTS;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0e17c2-1d55-4606-8afb-50c328caaaa2",
   "metadata": {
    "collapsed": false,
    "name": "cell29"
   },
   "source": [
    "# 2ï¸âƒ£ Data Visualization and Manipulation   \n",
    "- Exploring and querying the data with SQL and Python  \n",
    "- Basic visualizations using built-in charting tools  \n",
    "- Data cleaning and transformation using Python, SQL and Snowflake Cortex LLM Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d92cc-6d08-4a69-826a-8963b966c75c",
   "metadata": {
    "collapsed": false,
    "name": "cell8"
   },
   "source": [
    "### DATASET PILOT_1_PRODUCT_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2584fa27-1f29-4019-87e1-541934d661a5",
   "metadata": {
    "language": "python",
    "name": "cell30"
   },
   "outputs": [],
   "source": [
    "cluster_qualification_view = f'HOL_LAB_DATASCIENCE.{schema_name}.CLUSTER_QUALIFICATION'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c1889-ceee-4e43-803a-5bab40345a39",
   "metadata": {
    "collapsed": false,
    "name": "cell5"
   },
   "source": [
    "This SQL statement creates or replaces a **view** named `cluster_qualification_view`. The purpose of this view is to summarize and analyze **participant feedback** or **qualification scores** by **cluster**, providing average values for a series of CM (Customer Metrics or Qualification Metrics) fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0545bd-efd9-4145-84ed-04ff79c26fe7",
   "metadata": {
    "language": "sql",
    "name": "cell4"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE VIEW {{cluster_qualification_view}} AS (\n",
    "    SELECT\n",
    "    \tCLUSTER,\n",
    "    \tAVG(CM_OWN_WAY) AS CM_OWN_WAY_AVG,\n",
    "        AVG(CM_SECURE_SURROUNDINGS) AS CM_SECURE_SURROUNDINGS_AVG,\n",
    "        AVG(CM_GOOD_TIME) AS CM_GOOD_TIME_AVG,\n",
    "        AVG(CM_FOLLOW_RULES) AS CM_FOLLOW_RULES_AVG,\n",
    "        AVG(CM_DIFFERENT_PEOPLE) AS CM_DIFFERENT_PEOPLE_AVG,\n",
    "        AVG(CM_SATISFACTION) AS CM_SATISFACTION_AVG,\n",
    "        AVG(CM_SUCCESSFUL) AS CM_SUCCESSFUL_AVG,\n",
    "        AVG(CM_DEVOTE_MYSELF) AS CM_DEVOTE_MYSELF_AVG,\n",
    "        AVG(CM_TAKE_RISKS) AS CM_TAKE_RISKS_AVG,\n",
    "        AVG(CM_BE_IN_CHARGE) AS CM_BE_IN_CHARGE \n",
    "    FROM HOL_LAB_DATASCIENCE.LAB.CLUSTER_QUALIFICATION\n",
    "    WHERE CLUSTER is not null\n",
    "    GROUP BY CLUSTER\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b01d7d1-698e-47a6-8c85-2447a33eb58a",
   "metadata": {
    "language": "sql",
    "name": "cluster_calification"
   },
   "outputs": [],
   "source": [
    "SELECT * FROM {{cluster_qualification_view}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac5d232-5242-4022-9aaa-b8fce195f874",
   "metadata": {
    "collapsed": false,
    "name": "cell32"
   },
   "source": [
    "When working with multiple numerical vectors, it's often useful to compare how similar or different they are from one another. This can help in tasks like clustering, recommendation systems, or pattern recognition. Snowflake Notebooks facilitates this process by providing an easy way to interact between SQL and Python cells.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9738cf-ca3c-4e09-8beb-ed43a25aa75b",
   "metadata": {
    "language": "python",
    "name": "cell33"
   },
   "outputs": [],
   "source": [
    "df = cluster_qualification.to_pandas()\n",
    "good_friend = df[df[\"CLUSTER\"] == \"Good Friend\"].iloc[0,1:].values\n",
    "control_freak = df[df[\"CLUSTER\"] == \"Control Freak\"].iloc[0,1:].values\n",
    "cosine_similarity([good_friend], [control_freak])[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830c7da-f9df-47ef-a3b4-c0953841092b",
   "metadata": {
    "collapsed": false,
    "name": "cell31"
   },
   "source": [
    "### DATASET PILOT_1_E_COMMERCE_COMMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b242a8d-e219-4b60-998c-4160a6b3bff9",
   "metadata": {
    "collapsed": false,
    "name": "cell7"
   },
   "source": [
    "Snowflake has the ability to work directly with semi-structured data in SQL. This allows us to unpack JSON data without having to build out elaborate structures and more quickly extract information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7dee65a-8c7d-4f37-817b-20d61eb8fd4e",
   "metadata": {
    "language": "python",
    "name": "cell34"
   },
   "outputs": [],
   "source": [
    "top_mention_view = f'TRAINING_03_2025_DB.{schema_name}.TOP_MENTION'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13f085a-385c-4cd3-9b63-2e585b703b56",
   "metadata": {
    "language": "sql",
    "name": "Semi_Structured_Data"
   },
   "outputs": [],
   "source": [
    "SELECT\n",
    "    TOP 100 *\n",
    "FROM\n",
    "    TRAINING_03_2025_DB.DEMO.pilot_1_e_commerce_comments;\n",
    "CREATE OR REPLACE VIEW {{top_mention_view}} AS (\n",
    "        WITH parsed AS (\n",
    "            SELECT\n",
    "                PARSE_JSON(topics) AS p_topics,\n",
    "                *\n",
    "            FROM\n",
    "                TRAINING_03_2025_DB.DEMO.pilot_1_e_commerce_comments\n",
    "        ),\n",
    "        flattened AS (\n",
    "            SELECT\n",
    "                p.p_topics:positive AS positive,\n",
    "                p.p_topics:\"mentionned_topics\" AS mentioned_list,\n",
    "                topic.value AS topic,\n",
    "                p.*\n",
    "            FROM\n",
    "                parsed p,\n",
    "                LATERAL FLATTEN (input => p_topics:mentionned_topics) m,\n",
    "                LATERAL FLATTEN(strtok_to_array(m.value, ', ')) topic\n",
    "        )\n",
    "        SELECT\n",
    "            name_voysen,\n",
    "            topic,\n",
    "            count(*) AS \"Number of Mentions\"\n",
    "        FROM\n",
    "            flattened\n",
    "        GROUP BY\n",
    "            name_voysen,\n",
    "            topic\n",
    "    );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55848e0a-9303-464d-8cb1-58bac3400992",
   "metadata": {
    "collapsed": false,
    "name": "cell9"
   },
   "source": [
    "By building out the intermediate data models, we can build more interesting models on top of them to help gain insights.\n",
    "\n",
    "Note that the cell names will be used as references in subsequent cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4766c6-4608-44ae-9d0f-abe6fd94e2e8",
   "metadata": {
    "language": "sql",
    "name": "TOPICS_MENTIONED_BY_PRODUCT"
   },
   "outputs": [],
   "source": [
    "select \n",
    "    \n",
    "    Name_Voysen as Product, \n",
    "    Topic, \n",
    "    \"Number of Mentions\" as Mentions\n",
    "from {{top_mention_view}}\n",
    "QUALIFY RANK() OVER (PARTITION BY Name_Voysen ORDER BY \"Number of Mentions\" DESC) <=3\n",
    "order by Name_Voysen, \"Number of Mentions\" DESC;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbca399-19c5-4cd9-a7c6-0fe087a94082",
   "metadata": {
    "collapsed": false,
    "name": "cell11"
   },
   "source": [
    "Let's visualize our data by using Streamlit to display charts of the data we queried earlier using the cell names of the notebook as references."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd501ec9-8783-42fc-b10f-7d4603b5325c",
   "metadata": {
    "codeCollapsed": false,
    "language": "python",
    "name": "Topic_Mentions_Chart"
   },
   "outputs": [],
   "source": [
    "# this converts the results from the execution of the cell specified into data we can feed into our chart\n",
    "my_df = TOPICS_MENTIONED_BY_PRODUCT.to_pandas()\n",
    "\n",
    "# Chart the data\n",
    "st.subheader(\"Top 3 Topics Mentioned by Product\")\n",
    "st.bar_chart(my_df, x=\"PRODUCT\", y=\"MENTIONS\", color='TOPIC', stack=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0e85e1-e821-4372-8279-fa5020ee5238",
   "metadata": {
    "collapsed": false,
    "name": "cell35"
   },
   "source": [
    "We can use more advanced Python libraries, such as Plotly, to create richer and more interactive visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef3d84-7b1e-419a-bc3e-3be6b5f41348",
   "metadata": {
    "language": "python",
    "name": "cell10"
   },
   "outputs": [],
   "source": [
    "# Convert Snowpark DataFrame to pandas DataFrame\n",
    "my_df = TOPICS_MENTIONED_BY_PRODUCT.to_pandas()\n",
    "\n",
    "fig = px.bar(\n",
    "    my_df,\n",
    "    x=\"PRODUCT\",\n",
    "    y=\"MENTIONS\",\n",
    "    color=\"TOPIC\",\n",
    "    barmode=\"group\",  # Use \"stack\" for stacked bars\n",
    "    title=\"Top 3 Topics Mentioned by Product\",\n",
    "    labels={\"PRODUCT\": \"Product\", \"MENTIONS\": \"Number of Mentions\", \"TOPIC\": \"Topic\"},\n",
    ")\n",
    "\n",
    "st.plotly_chart(fig, use_container_width=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d21c00e-b278-4aba-aa6a-815d5264e329",
   "metadata": {
    "collapsed": false,
    "name": "cell38"
   },
   "source": [
    "# Data manipulation with Snowflake Cortex LLM Functions\n",
    "\n",
    "In this example, we demonstrate how to use **Snowflake Cortex LLM functions** to classify and clean free-text entries in a dataset, specifically leveraging the `CLASSIFY_TEXT` function to standardize product names.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ§  What is `CLASSIFY_TEXT`?\n",
    "\n",
    "`SNOWFLAKE.CORTEX.CLASSIFY_TEXT` is a Large Language Model (LLM) function provided by Snowflake Cortex. It allows you to match input text to the closest label in a list of predefined categories using AI, making it ideal for:\n",
    "- Text classification\n",
    "- Entity resolution\n",
    "- Standardization of messy input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c5143b-ce6d-4614-9e65-ba1c0af4f9a5",
   "metadata": {
    "language": "sql",
    "name": "cell37"
   },
   "outputs": [],
   "source": [
    "WITH base_query AS (\n",
    "    SELECT \n",
    "        PARSE_JSON(SNOWFLAKE.CORTEX.CLASSIFY_TEXT(\n",
    "            replace(name_source, '?', ''), \n",
    "            ['Chanel', 'Chanel N5', 'Dior', 'Chanel Chance', 'Chanel 520', \n",
    "             'Dior  Fahrenheit', 'Dior Ambre Nuit', ' Chanel Sensuelle', \n",
    "             'Chanel Allure', 'Chanel Allure Sport', 'Chanel Allure Sensuelle', \n",
    "             'Chanel Les 1957', 'ER', '72']\n",
    "        )):label::string AS name_source,\n",
    "        replace(name_source, '?', '') AS original_name_source\n",
    "    FROM TRAINING_03_2025_DB.DEMO.PILOT_1_E_COMMERCE_COMMENTS\n",
    "    LIMIT 1000\n",
    ")\n",
    "SELECT name_source, original_name_source \n",
    "FROM base_query;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46ee497-3c37-4e13-92e8-bd79c9c8d471",
   "metadata": {
    "collapsed": false,
    "name": "cell36"
   },
   "source": [
    "In this other example, we use **Snowflake Cortexâ€™s `COMPLETE` LLM function** to enhance the grammar of customer reviews while preserving the original tone and meaning. This is especially useful for cleaning up user-generated content before using it in dashboards, machine learning models, or customer-facing applications.\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸ¤– What is `SNOWFLAKE.CORTEX.COMPLETE`?\n",
    "\n",
    "The `COMPLETE` function allows you to interact with state-of-the-art Large Language Models (LLMs), like `mistral-large`, by passing **custom prompts**. This gives you flexibility to:\n",
    "- Rewrite or transform text\n",
    "- Generate structured output\n",
    "- Summarize, translate, or correct grammar\n",
    "- Answer domain-specific questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad104d-e72f-490f-8958-0bf18a7b99ac",
   "metadata": {
    "language": "sql",
    "name": "cell39"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    review_translated_text AS review_translated_text_original,\n",
    "    SNOWFLAKE.CORTEX.COMPLETE(\n",
    "        'mistral-large',\n",
    "        CONCAT(\n",
    "            'Correct the grammar of the following review, but keep the corrected version as similar as possible to the original review version. ',\n",
    "            'Do not add any explanations or labels. Only output the corrected version of the text: ',\n",
    "            review_translated_text,\n",
    "            ' Output:'\n",
    "        )\n",
    "    ) AS review_translated_text_improved\n",
    "FROM TRAINING_03_2025_DB.DEMO.PILOT_1_E_COMMERCE_COMMENTS\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "898368a4-25ee-4d98-979e-893012cdb3fb",
   "metadata": {
    "collapsed": false,
    "name": "cell41"
   },
   "source": [
    "We can combine multiple LLM function calls to accomplish more complex tasks. For example, we can translate the improved review text to French by just calling the Snowflake Cortex LLM function \"translate\".\n",
    "\n",
    "## ðŸŒ What is `SNOWFLAKE.CORTEX.TRANSLATE`?\n",
    "\n",
    "`SNOWFLAKE.CORTEX.TRANSLATE` is a built-in function that allows you to translate text between languages using AI models â€” directly within Snowflake.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076944d1-ce34-47cc-89d2-62840913b4f4",
   "metadata": {
    "language": "sql",
    "name": "cell40"
   },
   "outputs": [],
   "source": [
    "WITH base_query AS (\n",
    "    SELECT \n",
    "        review_translated_text AS review_translated_text_original,\n",
    "        SNOWFLAKE.CORTEX.COMPLETE(\n",
    "            'mistral-large',\n",
    "            CONCAT(\n",
    "                'Correct the grammar of the following review, but keep the corrected version as similar as possible to the original review version. ',\n",
    "                'Do not add any explanations or labels. Only output the corrected version of the text: ',\n",
    "                review_translated_text,\n",
    "                ' Output:'\n",
    "            )\n",
    "        ) AS review_translated_text_improved\n",
    "    FROM TRAINING_03_2025_DB.DEMO.PILOT_1_E_COMMERCE_COMMENTS\n",
    "    LIMIT 10\n",
    ")\n",
    "SELECT \n",
    "    review_translated_text_original,\n",
    "    review_translated_text_improved,\n",
    "    SNOWFLAKE.CORTEX.TRANSLATE(\n",
    "        review_translated_text_improved,\n",
    "        'en',\n",
    "        'fr'\n",
    "    ) AS review_translated_text_french\n",
    "FROM base_query"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e108d02d-2f60-4eda-9d01-fe3ef11560f0",
   "metadata": {
    "collapsed": false,
    "name": "cell42"
   },
   "source": [
    "# 3ï¸âƒ£ Snowflake ML Capabilities  \n",
    "- Overview of Snowflake Cortex ML functions  \n",
    "- Build a sample ML model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae51d53c-dc78-48c0-ac51-4f6d8bf4f3d1",
   "metadata": {
    "collapsed": false,
    "name": "cell2"
   },
   "source": [
    "First, let's define the data we will use for our machine learning use case. In this instance, we will utilize customer qualification scores to predict profile clusters. Before we proceed, let's use Snowflake to establish our model data table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9436e17e-bd86-4828-aa0f-1df2c538c30f",
   "metadata": {
    "language": "python",
    "name": "cell44"
   },
   "outputs": [],
   "source": [
    "model_data_table = f'TRAINING_03_2025_DB.{schema_name}.MODEL_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117bc452-5fec-40e6-ae72-3b9481c8df06",
   "metadata": {
    "language": "sql",
    "name": "cell12"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE {{model_data_table}} AS (\n",
    "    SELECT\n",
    "        ROW_NUMBER() OVER (ORDER BY RANDOM(42)) AS id,\n",
    "        CASE\n",
    "            WHEN CLUSTER = 'Good Friend' THEN 0\n",
    "            WHEN CLUSTER = 'Seeker' THEN 1\n",
    "            WHEN CLUSTER = 'Super Achiever' THEN 2\n",
    "            WHEN CLUSTER = 'Control Freak' THEN 3\n",
    "            WHEN CLUSTER = 'Traditionalist' THEN 4\n",
    "        END CLUSTER,\n",
    "    \tCM_OWN_WAY,\n",
    "    \tCM_SECURE_SURROUNDINGS,\n",
    "    \tCM_GOOD_TIME,\n",
    "    \tCM_FOLLOW_RULES,\n",
    "    \tCM_DIFFERENT_PEOPLE,\n",
    "    \tCM_SATISFACTION,\n",
    "    \tCM_SUCCESSFUL,\n",
    "    \tCM_DEVOTE_MYSELF,\n",
    "    \tCM_TAKE_RISKS,\n",
    "    \tCM_BE_IN_CHARGE\n",
    "    FROM TRAINING_03_2025_DB.DEMO.PILOT_1_PRODUCT_TEST\n",
    "    WHERE cluster IS NOT null \n",
    "    ORDER BY RANDOM(42)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05240ac8-597c-4ca3-b73b-e78b15116eb0",
   "metadata": {
    "collapsed": false,
    "name": "cell47"
   },
   "source": [
    "Next, let's split our data into training and test sets so we can build the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5af392-16ae-4630-b081-50c58a6e5c15",
   "metadata": {
    "language": "python",
    "name": "cell45"
   },
   "outputs": [],
   "source": [
    "train_table = f'TRAINING_03_2025_DB.{schema_name}.TRAIN_DATA'\n",
    "test_table = f'TRAINING_03_2025_DB.{schema_name}.TEST_DATA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f873fe-a7a8-4caf-b6f7-90dc7359a237",
   "metadata": {
    "language": "sql",
    "name": "cell13"
   },
   "outputs": [],
   "source": [
    "CREATE OR REPLACE TABLE {{train_table}} AS\n",
    "SELECT *\n",
    "FROM {{model_data_table}}\n",
    "SAMPLE (80);\n",
    "\n",
    "CREATE OR REPLACE TABLE {{test_table}} AS\n",
    "SELECT *\n",
    "FROM {{model_data_table}}\n",
    "WHERE id NOT IN (\n",
    "    SELECT id FROM {{train_table}}\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ab11ac-be54-4c7b-801d-1d4ed839567c",
   "metadata": {
    "collapsed": false,
    "name": "cell15"
   },
   "source": [
    "We can use the data in Snowflake to train our own model.\n",
    "\n",
    "## ðŸ“š Snowflake XGBoost Classifier\n",
    "\n",
    "The model used is [`snowflake.ml.modeling.xgboost.XGBClassifier`](https://docs.snowflake.com/en/developer-guide/snowpark-ml/reference/1.0.9/api/modeling/snowflake.ml.modeling.xgboost.XGBClassifier), a Snowflake-provided wrapper around the popular XGBoost algorithm for classification tasks. It integrates seamlessly with Snowpark DataFrames and supports in-database machine learning workflows.\n",
    "\n",
    "### ðŸ”‘ Key Features:\n",
    "- Accepts both **Snowpark DataFrames** and **Pandas DataFrames**.\n",
    "- Simplifies specifying **input**, **label**, and **output** columns.\n",
    "- Supports common XGBoost hyperparameters (`n_estimators`, `max_depth`, etc.).\n",
    "- Can be integrated into Snowflake's end-to-end ML lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdabcd4-ebd6-4983-97f2-34f2295f27f9",
   "metadata": {
    "language": "python",
    "name": "cell16"
   },
   "outputs": [],
   "source": [
    "train_df = session.table(train_table).to_pandas().head(1000) # We are using only 1000 samples for testing. Feel free to increase this value.\n",
    "test_df = session.table(test_table).to_pandas()\n",
    "\n",
    "model = XGBClassifier(\n",
    "    input_cols=['CM_OWN_WAY','CM_SECURE_SURROUNDINGS','CM_GOOD_TIME','CM_FOLLOW_RULES','CM_DIFFERENT_PEOPLE','CM_SATISFACTION','CM_SUCCESSFUL','CM_DEVOTE_MYSELF','CM_TAKE_RISKS','CM_BE_IN_CHARGE'],\n",
    "    label_cols=['CLUSTER'],\n",
    "    output_cols=[\"PREDICTED_CLUSTER\"],\n",
    "    n_estimators=200,\n",
    ")\n",
    "\n",
    "# Train\n",
    "model.fit(train_df)\n",
    "\n",
    "# Predict\n",
    "result = model.predict(test_df)\n",
    "result[['CLUSTER', 'PREDICTED_CLUSTER']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020546f9-0f95-4613-a13b-d2af7bdc2cae",
   "metadata": {
    "collapsed": false,
    "name": "cell46"
   },
   "source": [
    "Finaly, let's verify the accuracy of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18c77d1e-c75f-4420-bcf1-494b6455c64d",
   "metadata": {
    "language": "python",
    "name": "cell14"
   },
   "outputs": [],
   "source": [
    "acc = accuracy_score(result[\"CLUSTER\"], result[\"PREDICTED_CLUSTER\"])\n",
    "acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afa0236-de24-45dd-bbc4-32cca1decb82",
   "metadata": {
    "collapsed": false,
    "name": "cell43"
   },
   "source": [
    "# 4ï¸âƒ£ Snowflake Model Registry  \n",
    "- Introduction to the Model Registry  \n",
    "- Registering and versioning a custom model  \n",
    "- Deploying a model for inference  \n",
    "- Tracking model metadata and performance metrics  \n",
    "- Invoking the model through SQL and Python  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8311208e-7aa2-4084-8815-695480869611",
   "metadata": {
    "collapsed": false,
    "name": "cell50"
   },
   "source": [
    "## ðŸŽ¯ What is the Model Registry?\n",
    "The **Snowflake Model Registry** is a centralized system to **store, manage, and deploy machine learning models** within Snowflake. It enables secure, versioned, and collaborative model management as part of a complete in-database ML lifecycle using **Snowpark ML**.\n",
    "\n",
    "The Model Registry in Snowflake is designed to:\n",
    "- **Register trained models** for future use.\n",
    "- **Version models** for better experiment tracking.\n",
    "- **Store metadata** like model name, version, input/output schema, and tags.\n",
    "- **Share models** across teams and projects.\n",
    "- **Deploy models** directly within Snowflake for scoring on Snowpark DataFrames.\n",
    "\n",
    "It allows data scientists and ML engineers to **reuse and deploy models consistently**, all while keeping data and model artifacts inside the Snowflake Data Cloud.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93016aeb-c5d7-48e2-b5cf-5fb24a53644b",
   "metadata": {
    "language": "python",
    "name": "cell26"
   },
   "outputs": [],
   "source": [
    "reg = Registry(session=session, database_name=\"TRAINING_03_2025_DB\", schema_name=schema_name)\n",
    "model_name = 'CLUSTER_CLASSIFICATION'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74114849-9d08-4d42-8e70-f85ae1cb21e2",
   "metadata": {
    "collapsed": false,
    "name": "cell49"
   },
   "source": [
    "This code registers the trained model into the **Snowflake Model Registry**, enabling versioning, reuse, and in-database deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6a8393-99a6-4221-b15f-82d1261c60f3",
   "metadata": {
    "language": "python",
    "name": "cell17"
   },
   "outputs": [],
   "source": [
    "# Let's first log the very first model we trained\n",
    "model_ver = reg.log_model(\n",
    "    model_name=model_name,\n",
    "    version_name='V7',\n",
    "    model=model,\n",
    "    sample_input_data=train_df.head(100), # to provide the feature schema\n",
    "    options={\"enable_explainability\": True, 'relax_version': True}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a1f8ad-a3ef-431f-bc9f-b7183b8843a9",
   "metadata": {
    "collapsed": false,
    "name": "cell51"
   },
   "source": [
    "We can include evaluation metrics and descriptive comments when registering a model to improve metadata tracking and documentation. Additionally, all registered models and their versions can be visualized directly in the Snowflake Model Registry, making it easier to monitor and manage the ML lifecycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62acc8be-e40d-475d-8df5-27cbe825c6c3",
   "metadata": {
    "language": "python",
    "name": "cell18"
   },
   "outputs": [],
   "source": [
    "# Add evaluation metric\n",
    "model_ver.set_metric(metric_name=\"accuracy\", value=acc)\n",
    "\n",
    "# Add a description\n",
    "model_ver.comment = \"This is the first iteration of our Cluster Multi-Class model. It is used for demo purposes.\"\n",
    "\n",
    "# Let's confirm they were added\n",
    "reg.get_model(model_name).show_versions()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec42222d-69aa-4a1c-ab2b-213b12c724b7",
   "metadata": {
    "collapsed": false,
    "name": "cell19"
   },
   "source": [
    "Finally, we can load the registered model by specifying its version, using either Python or SQL, depending on the deployment or inference workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98da0ce1-775f-4711-bd86-99e7feafbb01",
   "metadata": {
    "language": "python",
    "name": "cell21"
   },
   "outputs": [],
   "source": [
    "model_ver = reg.get_model(model_name).version('v1')\n",
    "result_sdf2 = model_ver.run(test_df, function_name=\"predict\")\n",
    "result_sdf2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74541bab-3ff0-42c3-bc88-59332ad517a2",
   "metadata": {
    "language": "python",
    "name": "cell20"
   },
   "outputs": [],
   "source": [
    "model_function = f'TRAINING_03_2025_DB.{schema_name}.CLUSTER_CLASSIFICATION!PREDICT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fae339a-a9f7-404e-aeb4-f76b5654d4d2",
   "metadata": {
    "language": "sql",
    "name": "cell22"
   },
   "outputs": [],
   "source": [
    "SELECT \n",
    "    cluster,\n",
    "    {{model_function}}(\n",
    "        CM_OWN_WAY,\n",
    "        CM_SECURE_SURROUNDINGS,\n",
    "        CM_GOOD_TIME,\n",
    "        CM_FOLLOW_RULES,\n",
    "        CM_DIFFERENT_PEOPLE,\n",
    "        CM_SATISFACTION,\n",
    "        CM_SUCCESSFUL,\n",
    "        CM_DEVOTE_MYSELF,\n",
    "        CM_TAKE_RISKS,\n",
    "        CM_BE_IN_CHARGE\n",
    "    ):PREDICTED_CLUSTER::string AS predicted_cluster\n",
    "FROM TRAINING_03_2025_DB.DEMO.MODEL_DATA;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Streamlit Notebook",
   "name": "streamlit"
  },
  "lastEditStatus": {
   "authorEmail": "FABIAN@INFOSTRUX.COM",
   "authorId": "5347399495138",
   "authorName": "TRNG_FABIAN",
   "lastEditTime": 1743006043527,
   "notebookId": "ymtmy32qfex3e2i6ejvb",
   "sessionId": "1388caaf-666a-4109-b980-21be88827b0a"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
